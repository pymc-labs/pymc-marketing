# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2025, PyMC Labs
# This file is distributed under the same license as the pymc-marketing
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: pymc-marketing local\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-23 20:57+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: es\n"
"Language-Team: es <LL@li.org>\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../source/notebooks/mmm/mmm_example.ipynb:10003
#: c654c6ecde9c431090d9169bad8e8945
msgid "MMM Example Notebook"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10005
#: e233bda1b29549e682bbbb1e37321f9f
msgid ""
"In this notebook we work out a simulated example to showcase the media "
"mix Model (MMM) API from `pymc-marketing`. This package provides a `pymc`"
" implementation of the MMM presented in the paper [Jin, Yuxue, et al. "
"“Bayesian methods for media mix modeling with carryover and shape "
"effects.” (2017)](https://research.google/pubs/pub46001/). We work with "
"synthetic data as we want to do *parameter recovery* to better understand"
" the model assumptions. That is, we explicitly set values for our adstock"
" and saturation parameters (see model specification below) and recover "
"them back from the model. The data generation process is as an adaptation"
" of the blog post [\"Media Effect Estimation with PyMC: Adstock, "
"Saturation & Diminishing "
"Returns\"](https://juanitorduz.github.io/pymc_mmm/) by [Juan "
"Orduz](https://juanitorduz.github.io/)."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10007
#: 25576bec10394ced920d6285e8c4aea1
msgid "Business Problem"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10009
#: 1f2428ee76dd46efa010434df0fa4f3d
msgid ""
"Before jumping into the data, let's first define the business problem we "
"are trying to solve. We are a marketing agency and we want to optimize "
"the marketing budget of a client. We have access to the following data:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10011
#: 1b8bdcbb0bff41049f991b4192dfe5b6
msgid "Sales data: weekly sales of the client."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10012
#: 5a5ef481ecc24a9490fbb7a4915c3262
#, python-brace-format
msgid ""
"Media spend data: weekly spend on different media channels (e.g. TV, "
"radio, online, etc.). In this example we consider 2 media channels: "
"$x_{1}$ and $x_{2}$."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10013
#: d33947a9b028419ea62d33efd66326fb
msgid "Domain knowledge:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10014
#: 6b4392cea8434eeaac6f267ca1cfd428
msgid ""
"We know that there has a been an positive sales trend which we believe "
"comes from a strong economic growth."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10015
#: 09bdbc00e20046c3bfc59b42d56ac519
msgid "We also know that there is a yearly seasonality effect."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10016
#: 1413dca18b704bb89178f4c299e9f92b
msgid ""
"In addition, we were informed about two outliers in the data during the "
"weeks `2019-05-13` and `2021-09-14`."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:10018
#: 989ab11882244e399c75943d17c318dd
msgid ""
"Given this information we can draw a Directed Acyclic Graph (DAG) or "
"graphical model of how we believe our variables are related. In other "
"words, represent how we believe our system is causally related."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30002
#: f006a3a2721b4131b2c54af9923e84df
msgid "In this example, we will consider a simple system where:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30003
#: e07261ece64a45cc9270e1f2c429f56a
#, python-brace-format
msgid "**Marketing**: It represents the actions generated by $x_{1}$ and $x_{2}$."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30004
#: f6ac4f22144f44f2b34624d25390abd8
msgid ""
"**Special Events**: Outliers on specific days, which are possibly given "
"by special dates."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30005
#: bf5790cd0ee1458c9624080aff6ef783
msgid ""
"**Exogenous Variables**: We will consider variables that are determined "
"by external factors, not determined in the model (E.g: Country economic "
"growth or weather conditions that determine seasonal behavior)."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30007
#: fc9ebc34e3df45749f55821b112b97c1
msgid ""
"Understanding this ecosystem is essential to create a model that reveals "
"the true causal signals and allows us to optimize our advertising budget."
" But, What do we mean by optimize the marketing budget? We want to find "
"the optimal media mix that maximizes sales."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30009
#: fbcffc8518714204b92761a1594e4493
#, python-brace-format
msgid ""
"Now, given the DAG outlined above, we understand that there is a causal "
"relationship between marketing and sales, but *what is the nature of that"
" relationship*? In this case, we will assume that this relationship is "
"not linear, for example, a $10\\%$ increase in channel $x_{1}$ spend does"
" not necessarily translate into a $10\\%$ increase in sales. This can be "
"explained by two phenomena:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30011
#: 0e63a0e40ebb40a3bd6a4b5a62e74ded
msgid ""
"On the one hand side, there is a carry-over effect. Meaning, the effect "
"of spend on sales is not instantaneous but accumulates over time."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30012
#: 3bf8a76ad7b84a6d8485ce2130923490
msgid ""
"In addition, there is a saturation effect. Meaning, the effect of spend "
"on sales is not linear but saturates at some point."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30014
#: 66e71958656e4d868a48b1b36b048188
#, python-brace-format
msgid ""
"The equation implemented to describe the DAG presented above will be the "
"one expressed in [Jin, Yuxue, et al. “Bayesian methods for media mix "
"modeling with carryover and shape effects.” "
"(2017)](https://research.google/pubs/pub46001/), adding a causal "
"assumption around the media effects and their exclusively positive "
"impact. Concretely, given a time series target variable $y_{t}$ (e.g. "
"sales or conversions), media variables $x_{m, t}$ (e.g. impressions, "
"clicks or costs) and a set of control covariates $z_{c, t}$ (e.g. "
"holidays, special events) we consider a linear model of the form"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30016
#: fdb41fe275f6472cbb0a772560581633
#, python-brace-format
msgid ""
"\n"
"y_{t} = \\alpha + \\sum_{m=1}^{M}\\beta_{m}f(x_{m, t}) +  "
"\\sum_{c=1}^{C}\\gamma_{c}z_{c, t} + \\varepsilon_{t},\n"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30020
#: 079b964f1c0246b69d4cd483448769db
#, python-brace-format
msgid ""
"where $\\alpha$ is the intercept, $f$ is a media transformation function "
"and $\\varepsilon_{t}$ is the error term which we assume is normally "
"distributed. The function $f$ encodes the positive media contribution on "
"the target variable. Typically we consider two types of transformation: "
"adstock (carry-over) and saturation effects."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:30022
#: 6157f0a4a6c046be86f74f122a0e6ed1
msgid ""
"In **PyMC-Marketing**, we offer an API for a Bayesian Media Mix Model "
"(MMM) with various specifications. In the example, we’ll implement "
"`Geometric Adstock` and `Logistic Saturation` as the chosen "
"transformations for our previously discussed Structural Causal Equation."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40003
#: 7b43dcb2635b48c3b2963cf8a7666098
msgid ""
"The MMM model in `pymc-marketing` provides additional features on top of "
"this base model:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40005
#: fdaaa1e14ef6462890d760a2ac385437
#, python-brace-format
msgid ""
"**Experiment Calibration**: We have the option to add empirical "
"experiments (lift tests) to calibrate the model using custom likelihood "
"functions. See {ref}`mmm_lift_test`."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40007
#: 8eb648e94a474a36b02c1871a41fc1bb
#, python-brace-format
msgid ""
"**Time-varying Intercept:** Capture time-varying baseline contributions "
"in your model (using modern and efficient Gaussian processes "
"approximation methods). That is, we allow the intercept term $\\alpha = "
"\\alpha(t)$ to vary over time. See {ref}`mmm_tvp_example`."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40009
#: 4704fcdd2afd4691b0a9a20908b76add
#, python-brace-format
msgid ""
"**Budget Optimization:** Allocate your marketing budget based on the "
"parameters recover by the model, finding the spend distribution to "
"maximizes the amount of contribution given a limited budget. See "
"{ref}`mmm_budget_allocation_example`."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40012
#: 000aadb21b0342249f32c7a2edf9aa8e
msgid "References:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40014
#: 1dcc217073bd47d58a0a9baf70905849
msgid ""
"[Jin, Yuxue, et al. “Bayesian methods for media mix modeling with "
"carryover and shape effects.” "
"(2017).](https://research.google/pubs/pub46001/)"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40015
#: c06af3184b31401299d550def85ac3b2
msgid "PyMC Labs Blog:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40016
#: 43da25de100549a5a9477ab927509f7d
msgid ""
"[Bayesian Media Mix Modeling for Marketing Optimization](https://www"
".pymc-labs.com/blog-posts/bayesian-media-mix-modeling-for-marketing-"
"optimization/)"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40017
#: 4dfddff9d5b743a2acabbc20a7067424
msgid ""
"[Improving the Speed and Accuracy of Bayesian Media Mix "
"Models](https://www.pymc-labs.com/blog-posts/reducing-customer-"
"acquisition-costs-how-we-helped-optimizing-hellofreshs-marketing-budget/)"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40018
#: daffe6f7e4da450db92a5094d5f9f23e
msgid ""
"[Johns, Michael and Wang,  Zhenyu. \"A Bayesian Approach to Media Mix "
"Modeling\"](https://www.youtube.com/watch?v=UznM_-_760Y)"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:40019
#: 07eef60cdea84b37884a310647550516
msgid ""
"[Orduz, Juan. \"Media Effect Estimation with PyMC: Adstock, Saturation & "
"Diminishing Returns\"](https://juanitorduz.github.io/pymc_mmm/)"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:50004
#: e50764e75bf548429ac07663827c9e9c
msgid "Part I: Data Generation Process"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:50006
#: 5895e85a512d41b8b317fdded92f0e3e
#, python-brace-format
msgid ""
"In Part I of this notebook we focus on the data generating process. That "
"is, we want to construct the target variable $y_{t}$ (sales) by adding "
"each of the components described in the *Business Problem* section."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:50008
#: 71f02e40801c4588aa9cfdf5f5795d72
msgid "Prepare Notebook"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:70002
#: e9257084361c4f0facf405f127d01f1b
msgid "Generate Data"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:80002
#: a8ce4ee273ae4538b5e4ad24e4c466e3
msgid "1. Date Range"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:80004
#: 08874b90c0614dc59c803789d8889922
msgid ""
"First we set a time range for our data. We consider a bit more than 2 "
"years of data at weekly granularity."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:100002
#: bcfa757a23534d32b1d933e6948cca45
msgid "2. Media Costs Data"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:100004
#: b1475dd0cf49410099a62288ba59f679
msgid ""
"Now we generate synthetic data from two channels $x_1$ and $x_2$. We "
"refer to it as the raw signal as it is going to be the input at the "
"modeling phase. We expect the contribution of each channel to be "
"different, based on the carryover and saturation parameters."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:110002
#: 217a85cfb6c6409680faa9bed6888969
msgid "Raw Signal"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:130002
#: d420d07babe1474093a8f9644f72d4cc
#, python-brace-format
msgid ""
"**Remark:** By design, $x_{1}$ should resemble a typical paid social "
"channel and $x_{2}$ a offline (e.g. TV) spend time series."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:140002
#: d1d70f7ea81c435cbcb553786a29af60
msgid "Effect Signal"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:140004
#: cf076876e55c496492ee05bdc74464f2
msgid ""
"Next, we pass the raw signal through the two transformations: first the "
"geometric adstock (carryover effect) and then the logistic saturation. "
"Note that we set the parameters ourselves, but we will recover them back "
"from the model."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:140006
#: 2cefc689bdfa4c9289d0a5f8d10a9916
msgid ""
"Let's start with the adstock transformation. We set the adstock parameter"
" $0 < \\alpha < 1$ to be $0.4$ and $0.2$ for $x_1$ and $x_2$ "
"respectively. We set a maximum lag effect of $8$ weeks."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:160002
#: 79a8c67dca6448fd8c61332aa9b00803
msgid ""
"Next, we compose the resulting adstock signals with the logistic "
"saturation function. We set the parameter $\\lambda > 0$ to be $4$ and "
"$3$ for $z_1$ and $z_2$ respectively."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:180002
#: acb8ed6cb8094680af94738ef7747db9
msgid ""
"We can now visualize the effect signal for each channel after each "
"transformation:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:200002
#: b7f006e865cd4d15854f32a3bb906104
msgid "3. Trend \\& Seasonal Components"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:200004
#: 5bbd13ce211c4f34b2bf47919d4ee720
msgid "Now we add synthetic trend and seasonal components to the effect signal."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:220002
#: 30133d26876f49de92f8ad1c9c7bdd1c
msgid "4. Control Variables"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:220004
#: 8af8f719029b4577babfaec3f8ddb6de
msgid ""
"We add two *events* where there was a remarkable peak in our target "
"variable. We assume they are independent and not seasonal (e.g. launch of"
" a particular product)."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:240002
#: b515646445234329a03f820dcb4826c5
msgid "5. Target Variable"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:240004
#: 51497ce0849e438586285969d6105bec
msgid ""
"Finally, we define the target variable (sales) $y$. We assume it is a "
"linear combination of the effect signal, the trend and the seasonal "
"components, plus the two events and an intercept. We also add some "
"Gaussian noise."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:260002
#: 26dbc31c039d44aca13e64937968f1c5
msgid ""
"We can visualize the true component contributions over the historical "
"period:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:280002
#: cc8777a1fa344d12af993ccbe1fc1d11
msgid "We would like to recover these values from the model."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:290002
#: 50502ce1494b4c02891adf5ec013b02b
msgid "6. Media Contribution Interpretation"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:300002
#: 15e59c74c11c457e82d62ce0f2f4092e
msgid ""
"From the data generating process we can compute the relative contribution"
" of each channel to the target variable. We will recover these values "
"back from the model."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:320002
#: bb9dedabfec24c8aa991745be80f5102
msgid ""
"We can obtain the contribution plots for each channel where we clearly "
"see the effect of the adstock and saturation transformations."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:340002
#: 8a900029db834e029d88e5df1c847f16
msgid "This plot shows some interesting aspects of the media contribution:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:340004
#: 738caf0c01ce466fb95c2d0068cebba6
msgid ""
"The adstock effect is reflected in the non-zero contribution of the "
"channel even when the spend is zero."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:340005
#: 8d4ae27946164890a9e86a173f8af340
msgid ""
"One clearly see the saturation effect as the contribution growth (slope) "
"decreases as the spend increases."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:340007
#: ec8d10736abe4f37808e55a90a0f7f91
msgid ""
"As we will see in Part II of this notebook, we will recover these plots "
"from the model!"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:350002
#: 1e85e427b059412690b89b17397aff21
#, python-brace-format
msgid ""
"We see that channel $x_{1}$ has a higher contribution than $x_{2}$. This "
"could be explained by the fact that there was more spend in channel  "
"$x_{1}$ than in channel $x_{2}$:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:370002
#: 3b990191718542c9818b2d2314e2b9c7
msgid ""
"However, one usually is not only interested in the contribution itself "
"but rather the Return on Ad Spend (ROAS). That is, the contribution "
"divided by the cost. We can compute the ROAS for each channel as follows:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:400002
#: e3df27f6a3ef4508abb0d5f03f43fb6b
#, python-brace-format
msgid "That is, channel $x_{1}$ seems to be more efficient than channel $x_{2}$."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:410003
#: a9a86210b4ec40909605d49c4d676986
msgid ""
"We recommended reading Section 4.1 in [Jin, Yuxue, et al. “Bayesian "
"methods for media mix modeling with carryover and shape effects.” "
"(2017)](https://research.google/pubs/pub46001/) for a detailed "
"explanation of the ROAS (and mROAS). In particular:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:410005
#: ecf9d5f92f5d4bf7afa86c867c739546
msgid ""
"If we transform our target variable $y$ (e.g. with a log transformation),"
" one needs to be careful with the ROAS computation as setting the spend "
"to zero does not commute with the transformation."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:410007
#: 060b6b39613c40a685a01052b9c26681
msgid ""
"One has to be careful with the adstock effect so that we include a "
"carryover period to fully account for the effect of the spend. The ROAS "
"estimation above is an approximation."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:420002
#: 1238bdd6e4024781bd7bb21a0973eef7
msgid "7. Data Output"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:430002
#: 3104429c7e9b459593a135e83eed17e6
msgid ""
"We of course will not have all of these features in our real data. Let's "
"filter out the features we will use for modeling:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:450002
#: c6c7017f20b84261b3859733a10e2135
msgid "Part II: Modeling"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:450004
#: 63c7a30627b044bb88ddcc0040585d7d
msgid ""
"On this second part, we focus on the modeling process. We will use the "
"data generated in Part I."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:450006
#: 1870e86c7c3e42acb5611efa3cdb9c48
msgid "1. Feature Engineering"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:450008
#: ae1f7c052a8c4d809622b459472bb834
msgid ""
"Assuming we did an EDA and we have a good understanding of the data (we "
"did not do it here as we generated the data ourselves, but please never "
"skip the EDA!), we can start building our model. One thing we immediately"
" see is the seasonality and the trend component. We can generate features"
" ourselves as *control variables*, for example using a uniformly "
"increasing straight line to model the trend component. In addition, we "
"include *dummy variables* to encode the `event_1`  and `event_2` "
"contributions."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:450010
#: d19cf58052074d4692ad1791af3a6dc6
msgid ""
"For the seasonality component we use Fourier modes (similar as in "
"[Prophet](https://facebook.github.io/prophet/)). We do not need to add "
"the Fourier modes by hand as they are handled by the model API through "
"the `yearly_seasonality` argument (see below). We use 4 modes for the "
"seasonality component."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:470002
#: b0011bbe624945e7bcee4d6f35f448c5
msgid "2. Model Specification"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:480002
#: 08fedceae2324b69a4507fb1504d9276
#, python-brace-format
msgid ""
"We can specify the model structure using the {class}`MMM "
"<pymc_marketing.mmm.mmm.MMM>` class. This class, handles a lot of "
"internal boilerplate code for us such us scaling the data (see details "
"below) and handy diagnostics and reporting plots. One great feature is "
"that we can specify the channel priors distributions ourselves, which "
"fundamental component of the [bayesian "
"workflow](https://arxiv.org/abs/2011.01808) as we can incorporate our "
"prior knowledge into the model. This is one of the most important "
"advantages of using a bayesian approach. Let's see how we can do it."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:480004
#: 8a1b028d82c645ee84494616c2d7eb10
msgid ""
"As we do not know much more about the channels, we start with a simple "
"heuristic:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:480006
#: ba7f7a9ac0fc427faac1c47145dbf4fb
#, python-brace-format
msgid ""
"The channel contributions should be positive, so we can for example use a"
" {class}`HalfNormal <pymc.distributions.continuous.HalfNormal>` "
"distribution as prior. We need to set the `sigma` parameter per channel. "
"The higher the `sigma`, the more \"freedom\" it has to fit the data. To "
"specify `sigma` we can use the following point."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:480008
#: 4ec9144e7317470192815b83910274d9
msgid ""
"We expect channels where we spend the most to have more attributed sales "
", before seeing the data. This is a very reasonable assumption (note that"
" we are not imposing anything at the level of efficiency!)."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:480010
#: b845db6cca1d482c99028ade1271a11e
#, python-brace-format
msgid ""
"How to incorporate this heuristic into the model? To begin with, it is "
"important to note that the {class}`MMM <pymc_marketing.mmm.mmm.MMM>` "
"class scales the target and input variables through an "
"[`MaxAbsScaler`](https://scikit-"
"learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)"
" transformer from [`scikit-learn`](https://scikit-learn.org/stable/), its"
" important to specify the priors in the scaled space (i.e. between 0 and "
"1). One way to do it is to use the spend share as the `sigma` parameter "
"for the `HalfNormal` distribution. We can actually add a scaling factor "
"to take into account the support of the distribution."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:480012
#: 90e71ea5532c4b7a959776d2ecf7fcd9
msgid "First, let's compute the share of spend per channel:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:500002
#: c0425678bfb74dcfb7b61143d00627e4
msgid "Next, we specify the `sigma` parameter per channel:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:510002
#: dcc7339b1ab44c99be7097b06983e995
msgid "\\displaystyle \\left[ 1.31263902694007, \\  0.687360973059932\\right]"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:520002
#: 76252e67bee847a6b66b7a4981bfc4e6
msgid ""
"Delayed Saturated MMM follows sklearn convention, so we need to split our"
" data into X (predictors) and y(target value)"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:540002
#: 698a671cf8004c63b95479974efff77a
msgid ""
"You can use the optional parameter 'model_config' to apply your own "
"priors to the model. Each entry in the 'model_config' contains a key that"
" corresponds to a registered distribution name in our model. The value of"
" the key is a dictionary that describes the input parameters of that "
"specific distribution."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:540004
#: 7d38270be39442aba296d18ad9502b10
#, python-brace-format
msgid ""
"If you're unsure how to define your own priors, you can use the "
"'default_model_config' property of {class}`MMM "
"<pymc_marketing.mmm.mmm.MMM>` to see the required structure."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:560002
#: c72c00f260fc49a29a0f054852a3c4ea
msgid ""
"You can change only the prior parameters that you wish, no need to alter "
"all of them, unless you'd like to!"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:580002
#: a7dcf3bb6a1e4f2999d558345c7d0804
#, python-brace-format
msgid ""
"**Remark:** For the prior specification there is no right or wrong "
"answer. It all depends on the data, the context and the assumptions you "
"are willing to make. It is always recommended to do some prior predictive"
" sampling and sensitivity analysis to check the impact of the priors on "
"the posterior. We skip this here for the sake of simplicity. If you are "
"not sure about specific priors, the {class}`MMM "
"<pymc_marketing.mmm.mmm.MMM>` class has some default priors that you can "
"use as a starting point."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:590002
#: 6d70f32a9bde4120bd2962437ac6b75c
#, python-brace-format
msgid ""
"Model sampler allows specifying set of parameters that will be passed to "
"fit the same way as the `kwargs` are getting passed so far. It doesn't "
"disable the fit kwargs, but rather extend them, to enable customizable "
"and preservable configuration. By default the sampler_config for "
"{class}`MMM <pymc_marketing.mmm.mmm.MMM>` is empty. But if you'd like to "
"use it, you can define it like showed below:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:610002
#: aed0e8cc54b84e149daed22baa05c845
#, python-brace-format
msgid ""
"Now we are ready to use the {class}`MMM <pymc_marketing.mmm.mmm.MMM>` "
"class to define the model."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:630002
#: 7b318837026b4abe9c0bd7999fb3455c
msgid "Observe how the media transformations were handled by the class `MMM`."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:640002
#: 6be7d08cb7964f07a75c65dd6b9222d8
msgid ""
"To assess the model prior parameters we can look into the prior "
"predictive plot:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:660002
#: 3c1d6db327ed45e2bd29ccc46b370bd6
msgid "The prior predictive plot shows that the priors are not too informative."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:670002
#: d495fbf7fc2e4648a991accd90e92687
msgid "3. Model Fitting"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:680002
#: 492b99e061014deead8456765fd7a093
msgid "We can now fit the model:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:690003
#: f0306d3964e94066b1fe8e19c8fb4f40
#, python-brace-format
msgid ""
"You can use other NUTS samplers to fit the model as one can do with PyMC "
"models. You just need to make sure to have the packages installed in your"
" local environment. See {ref}`other_nuts_samplers`."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:710002
#: f60ef0cbc7c9438d9d5d20ef1d640a28
msgid "You can access `pymc` model as `mmm.model`."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:740002
#: ebef060df5ea40e9a09cc4d50372aa8d
msgid "We can easily see the explicit model structure:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:760002
#: d4ca46110c7b49b5a10953a8447f7654
msgid ""
"Note: You may notice that the graph here is an explicit version of our "
"initial drawing (DAG), where we can now explicitly see all the different "
"components that were included in each node, including their "
"dimensionality. This graph is another way of looking at the same causal "
"assumptions, made during the construction of the bayesian generative "
"model."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:770002
#: cdc6a35184c54048a23b7af8ceed700f
msgid "4. Model Diagnostics"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:780002
#: 5960a500da8b43e3b60c01d71f4993bb
msgid "A good place to start is by looking if the model had any divergences:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:790002
#: ea2a4e2f2ee84b4db4036996b681bfd1
msgid "\\displaystyle 0"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:800002
#: c2f4c343e64a416bb3ef0197d4938b1f
msgid "We got none! 🙌"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:810002
#: 2f22890d66ed435bb554b54796bde2c3
#, python-brace-format
msgid ""
"The {func}`fit_result <pymc_marketing.mmm.mmm.MMM.fit_result>` attribute "
"contains the `pymc` trace object."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:830002
#: c06e48fc4aed4a0c962273d9c9d36439
msgid ""
"We can therefore use all the `pymc` machinery to run model diagnostics. "
"First, let's see the summary of the trace:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:850002
#: 379439c3c4a84fd187357cae192390a6
msgid ""
"Observe that the estimated parameters for $\\alpha$ and $\\lambda$ are "
"very close to the ones we set in the data generation process! Let's plot "
"the trace for the parameters:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:870002
#: ba3ff60fbe5f48d788cfba59db475d34
msgid "Now we sample from the posterior predictive distribution:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:890002
#: 69d93b3ad2fd42de813a90afe69b9ebf
msgid ""
"We can now plot the posterior predictive distribution for the target "
"variable. By default, the `plot_posterior_predictive` method will plot "
"the mean prediction along with a 94% and 50% HDI."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:910002
#: 4c018064463f4c7596daf60fed330aa6
msgid ""
"But you can also remove the mean and HDI and add a gradient, which shows "
"the range of the posterior predictive distribution."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:930002
#: 95ce9854541d47b9ba7bdc77ea485de5
msgid "The fit looks very good (as expected)!"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:940002
#: eee0501a7c684d54b312db0412af79cd
msgid "We can inspect the model errors:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:960002
#: 94fc94623711446e91969fa02baa13b5
msgid ""
"We can actually extract the whole error posterior distribution for custom"
" error analyzes:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:990002
#: af1c38c504554c48aa6c03892bd6f05c
msgid ""
"Next, we can decompose the posterior predictive distribution into the "
"different components:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1010002
#: c7232e02e45d43f4a29d349e0a45e99a
msgid ""
"**Remark:** This plot shows the decomposition of the normalized target "
"variable when by dividing by its maximum value. Do not forget that "
"internally we are scaling the variables to make the model sample more "
"efficiently. You can recover the transformations from the API methods, "
"e.g."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1030002
#: 65ac64437c9545779a994aae83f07bc0
msgid ""
"We plot in the original scale by simply passing the `original_scale=True`"
" argument:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1050002
#: 642d109fb22b46239ba55642f02d6241
msgid "A similar decomposition can be achieved using an area plot:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1070002
#: 00dad88791f840b3a72fc7591ad77ce7
msgid ""
"Note that this only works if the contributions of the channel or control "
"variable are strictly positive."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1080002
#: 377ec6bf16f945dbb561ffde859ca9a5
msgid ""
"Next, we look into the absolute historical contributions of each "
"component:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1100002
#: 4f7328abec9b41a1a9b1bc2f9c83636a
msgid ""
"Note that we have recovered the true values for all the parameters! Well,"
" in fact the contributions of the `intercept` and `t` are not exactly the"
" same as int the data generating process, but the aggregate does match "
"the true values of `intercept` + `trend`. The reason is that the true "
"latent trend is not completely linear. One could use the time-varying "
"intercept feature to capture this effect."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1110002
#: eac53829320e4ed8a7a4f31fa34e70a8
msgid ""
"We can extract the data itself of all the input variables contributions "
"over time, i.e. the regression coefficients times the feature values, as "
"follows:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1130002
#: ef4e288cf3fe4068a0170ca6bef66e78
msgid "5. Media Parameters"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1130004
#: c71dce08de66450fb63f42bae6d26159
msgid ""
"We can deep-dive into the media transformation parameters. We want to "
"compare the posterior distributions against the true values."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1160002
#: a35b13f52fd8472b9cac147ae8c5ddf2
msgid "We indeed see that our media parameter were successfully recovered!"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1170002
#: ca152a7e026c49b781d70be1fa984119
msgid "6. Media Deep-Dive"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1170004
#: 3be1e0b048e74a8bbe9f709d36042561
msgid ""
"First we can compute the relative contribution of each channel to the "
"target variable. Note that we recover the true values!"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1190002
#: 75fd0374199f4c5cbd5ae9e6a29c46d4
msgid ""
"Next, we can plot the relative contribution of each channel to the target"
" variable."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1190004
#: 373ec763d8fa4623872fa101e36e0fda
msgid ""
"First we plot the **direct contribution** per channel. Again, we get very"
" close values as the ones obtained in Part I."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1210002
#: c725354e669f46439b191e85f4c402c5
msgid ""
"Note that trying to get the delayed cumulative contribution is not that "
"easy as contributions from the past leak into the future. Specifically, "
"note that we apply the saturation function to the aggregation. As the "
"saturation function is non-linear. This is not the same as taking the sum"
" of the saturation contributions Hence, is very hard to reverse engineer "
"the contribution after carryover and saturation composition this way."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1210004
#: 4db3eab59f6d48af8604a355466f2a1f
msgid ""
"A more transparent alternative is to evaluate the channel contribution at"
" different share spend levels for the complete training period. "
"Concretely, if the denote by $\\delta$ the input channel data percentage "
"level, so that for $\\delta = 1$ we have the model input spend data and "
"for $\\delta = 1.5$ we have a $50\\%$ increase in the spend, then we can "
"compute the channel contribution at a grid of $\\delta$-values and plot "
"the results:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1230002
#: b1d5e7b4475042c5854dbb14fd7ddaa2
msgid "This plot does account for carryover (adstock) and saturation effects."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1230003
#: 56d0311842ed4994a0edb8a006124424
msgid ""
"We see that when we have no spend, the contribution is zero (assuming "
"there twas no spend in the past, otherwise the carryover effect would be "
"non-zero)."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1230005
#: 69f5c48dc3574c3fa0eb51af25f34765
msgid "Observe that these grid values serve as inputs for an optimization step."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1240002
#: c7e420e4723a43f8bbba212b9b0f93e5
msgid ""
"We can also plot the same contribution using the x-axis as the total "
"channel input (e.g. total spend in EUR)."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1260002
#: 2526ad4ac23d4e85a635b6efae036e78
msgid "7. Contribution  Recovery"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1270002
#: 04563acb28ec4090a1285d10d6360dda
msgid ""
"Next, we can plot the direct contribution of each channel to the target "
"variable over time."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1290002
#: 0356012c322645179992104095defc49
#, python-brace-format
msgid ""
"The results look great! We therefore successfully recovered the true "
"values from the data generation process. We have also seen how easy is to"
" use the {class}`MMM <pymc_marketing.mmm.mmm.MMM>` class to fit media mix"
" models! It takes over the model specification and the media "
"transformations, while having all the flexibility of `pymc`!"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1300002
#: 4efbb412926d4d64ab66eb96256dabcc
msgid "8. ROAS"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1300004
#: d3931497e5da4300a6f3cca146b28586
msgid ""
"Finally, we can compute the (approximate) ROAS posterior distribution for"
" each channel."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1320002
#: ef93cdb55d2c4866b21545d07711a964
#, python-brace-format
msgid ""
"We see that the ROAS posterior distributions are centered around the true"
" values! We also see that, even considering the uncertainty, channel "
"$x_{1}$ is more efficient than channel $x_{2}$."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1330002
#: 2f627d96a4e241b3870cb4ba25cb73c2
msgid ""
"It is also useful to compare the ROAS and the contribution share. In the "
"next plot we plot these two these two inferred estimates per channel."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1350002
#: 825f855888d648d6af6f121c03a20b02
msgid ""
"This plot is very effective summarizing channel efficiency. In this "
"example, it turns out that the most efficient channel $x_1$ has a higher "
"contribution share than the less efficient channel $x_2$."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1360002
#: 19649018ccd74277bddcc2682cbd0e5b
msgid "9. Out of Sample Predictions"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1360004
#: 279e53f1452940e1bf37f41aaeff1b01
msgid ""
"Out of sample predictions are done with the `predict` and "
"`posterior_predictive` methods. These include"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1360006
#: 2579b37a99d04337b2994095699bd007
msgid ""
"`sample_posterior_predictive` : Get the full posterior predictive "
"distribution"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1360007
#: a31936c066eb4150985701e1fb6c98ed
msgid "`predict`: Get the mean of the posterior predictive distribution"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1360009
#: ec3459e7e4eb42a69ea1ca20d3dc10ae
msgid ""
"These methods take new data, `X`, and some additional `kwargs` for new "
"predictions. Namely,"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1360011
#: 6000af35ed754f1aa9048290510d6aeb
msgid ""
"`include_last_observations` : boolean flag in order to carry adstock "
"effects from last observations in the training dataset"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1370002
#: 6336c218674441c9bd042feb1286cc16
msgid ""
"The new data needs to have all the features that are specified in the "
"model. There is no need to worry about:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1370004
#: c22b61e3ef6043f3bae3f2308d8962ff
msgid "input scaling of channel spends"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1370005
#: 632f9f5a91df41d4947ad6ccb208c174
msgid "creating fourier transformations on the `date_column`"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1370006
#: dbfcb717d342422eb2e98d17be9d576e
msgid "inverse scaling back to target domain"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1370008
#: 2900a52789d5447dbfd56a862833d42a
msgid ""
"That will be done automatically! However, please note that control "
"variables are NOT automatically scaled - if needed, you must scale them "
"before passing the data to the model."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1390002
#: a7ddebd0c8244e39a0cb1ccaab298701
msgid ""
"Call the desired method to get the new samples! The new coordinates will "
"be from the new dates"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1420002
#: 06a8f059c3fb48cf82322f0bda7bc0eb
msgid ""
"**NOTE:** If the method is being called **multiple times**, set the "
"`extend_idata` argument to False in order to not overwrite the "
"`observed_data` in the `InferenceData`"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1430002
#: 390bdfd5aa4b4bc48107a3d5e50ed284
msgid ""
"The new predictions are transformed back to the original scale of the "
"target by default. That can be seen below:"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1450002
#: b055692042f7433597e2c3e5b56a0580
msgid ""
"If the out of sample data is being extended from the original "
"predictions, consider setting the `include_last_observations` to True in "
"order to carry over the effects from the last channel spends in the "
"training set."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1450004
#: e7d4d3f286194f6b960a4fd0b008dce3
msgid ""
"The predictions are higher since the channel contributions the final "
"spends still have an impact that eventually subside."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1480002
#: f8ae4cec121f4d1384cc3f779b130f3b
msgid ""
"Finally we can use the model to understand the expected sales for "
"different media spend scenarios considering the adstock and saturation "
"effects learned from the data."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1500002
#: 1fd86e39625e4c64946ef3ebacecc9ec
msgid ""
"We clearly see that since $x_1$ has a higher adstock parameter $\\alpha$ "
"than $x_2$, then for new spend on a single date (i.e. `one_time`)  $x_1$ "
"has larger delayed contributions than $x_2$."
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1510002
#: 777f9ac3e988492ba9adf5df154c7253
msgid "10. Save Model"
msgstr ""

#: ../source/notebooks/mmm/mmm_example.ipynb:1510003
#: fe0bbecfd3904a7c932915bac0531362
#, python-brace-format
msgid ""
"After your model is train, you can quickly save it using the `save` "
"method. For more information about model deployment see "
"{ref}`model_deployment`."
msgstr ""

